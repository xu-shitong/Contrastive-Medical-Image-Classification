{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JR0Flq1UxNNA"
      },
      "source": [
        "# Download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rfzXouQxNNE",
        "outputId": "19f7d77d-dd7e-4358-e2ee-36d649faf595"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting medmnist\n",
            "  Downloading medmnist-2.1.0-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from medmnist) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from medmnist) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from medmnist) (1.0.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.8/dist-packages (from medmnist) (0.18.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from medmnist) (1.3.5)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from medmnist) (0.14.0+cu116)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from medmnist) (4.64.1)\n",
            "Collecting fire\n",
            "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 KB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from medmnist) (1.13.0+cu116)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from fire->medmnist) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from fire->medmnist) (2.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->medmnist) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->medmnist) (2022.7)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image->medmnist) (1.7.3)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image->medmnist) (2.8.8)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image->medmnist) (2022.10.10)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image->medmnist) (3.2.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image->medmnist) (1.4.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image->medmnist) (2.9.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->medmnist) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->medmnist) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->medmnist) (4.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision->medmnist) (2.25.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->medmnist) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->medmnist) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->medmnist) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision->medmnist) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision->medmnist) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision->medmnist) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision->medmnist) (1.24.3)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116949 sha256=b1a67f1e459d1c71ca365dafae8427fb1621e0956866e18aed42d00a88ec2adf\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/eb/43/7295e71293b218ddfd627f935229bf54af9018add7fbb5aac6\n",
            "Successfully built fire\n",
            "Installing collected packages: fire, medmnist\n",
            "Successfully installed fire-0.5.0 medmnist-2.1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.0+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gputil\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7409 sha256=2e7410344c2609941fbb0456a245b82892ec56a91c857179cc712bff8990938f\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/03/bb/7a97840eb54479b328672e15a536e49dc60da200fb21564d53\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (5.4.8)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.8/dist-packages (0.5.1)\n",
            "Fri Jan  6 17:29:04 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   62C    P0    30W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "WORKING_ENV = 'COLAB' # Can be LABS, COLAB or PAPERSPACE\n",
        "assert WORKING_ENV in ['LABS', 'COLAB', 'LOCAL']\n",
        "\n",
        "import sys\n",
        "if WORKING_ENV == 'COLAB':\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive/')\n",
        "  !pip install medmnist\n",
        "  !pip install torch\n",
        "  !pip install gputil\n",
        "  !pip install psutil\n",
        "  !pip install humanize\n",
        "  ROOT = \"/content/drive/MyDrive/ColabNotebooks/med-contrastive-project/\"\n",
        "  sys.path.append(ROOT + \"./moco/\")\n",
        "  !nvidia-smi\n",
        "elif WORKING_ENV == 'LABS':\n",
        "  ROOT = \"/vol/bitbucket/sx119/Contrastive-Medical-Image-Classification/\"\n",
        "else:\n",
        "  ROOT = \"/Users/xushitong/Contrastive-Medical-Image-Classification/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hR8ZgATBxNNG"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ygRaiz3zxNNG"
      },
      "outputs": [],
      "source": [
        "import medmnist\n",
        "\n",
        "import argparse\n",
        "import builtins\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import time\n",
        "import tqdm\n",
        "import warnings\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "# import torch.distributed as dist\n",
        "import torch.optim\n",
        "import torch.multiprocessing as mp\n",
        "import torch.utils.data\n",
        "# import torch.utils.data.distributed\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "\n",
        "import loader\n",
        "import builder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwggMf_Yw-i7",
        "outputId": "cee4b49b-5392-4433-93f3-d94e70e0a51a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU RAM Free: 12.4 GB\n",
            "GPU 0 ... Mem Free: 15109MB / 15109MB | Utilization   0%\n"
          ]
        }
      ],
      "source": [
        "# Import packages\n",
        "import os,sys,humanize,psutil,GPUtil\n",
        "\n",
        "# Define function\n",
        "def mem_report():\n",
        "  print(\"CPU RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ))\n",
        "  \n",
        "  GPUs = GPUtil.getGPUs()\n",
        "  for i, gpu in enumerate(GPUs):\n",
        "    print('GPU {:d} ... Mem Free: {:.0f}MB / {:.0f}MB | Utilization {:3.0f}%'.format(i, gpu.memoryFree, gpu.memoryTotal, gpu.memoryUtil*100))\n",
        "\n",
        "mem_report()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0-zL3BAxNNI"
      },
      "source": [
        "# Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSLD_2PmxNNI",
        "outputId": "d6371b3b-7a8e-45d6-c658-0aae0026d6b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running command ['--epochs', '1', '-b', '128', '--lr', '0.03', '--momentum', '0.9', '--print-freq', '100', '--gpu', '0', '/content/drive/MyDrive/ColabNotebooks/med-contrastive-project/./datasets']\n"
          ]
        }
      ],
      "source": [
        "EPOCH_NUM = 200\n",
        "BATCH_SIZE = 128\n",
        "LEARNING_RATE = 0.03\n",
        "MOMENTUM = 0.9\n",
        "\n",
        "trial_name = f\"epochs{EPOCH_NUM}_batch{BATCH_SIZE}_lr{LEARNING_RATE}_momentum{MOMENTUM}\"\n",
        "arg_command = f\"--epochs_{EPOCH_NUM}_-b_{BATCH_SIZE}_--lr_{LEARNING_RATE}_--momentum_{MOMENTUM}_--print-freq_100_{'' if WORKING_ENV == 'LOCAL' else '--gpu_0_'}{ROOT}./datasets\".split(\"_\")\n",
        "\n",
        "print(f\"Running command {arg_command}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ct1yDbRsxNNJ",
        "outputId": "71988c7c-3942-4781-e400-9b957169eb65"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "_StoreTrueAction(option_strings=['--cos'], dest='cos', nargs=0, const=True, default=False, type=None, choices=None, help='use cosine lr schedule', metavar=None)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#!/usr/bin/env python\n",
        "# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved\n",
        "\n",
        "model_names = sorted(name for name in models.__dict__\n",
        "    if name.islower() and not name.startswith(\"__\")\n",
        "    and callable(models.__dict__[name]))\n",
        "\n",
        "parser = argparse.ArgumentParser(description='PyTorch ImageNet Training')\n",
        "parser.add_argument('data', metavar='DIR',\n",
        "                    help='path to dataset')\n",
        "parser.add_argument('-a', '--arch', metavar='ARCH', default='resnet50',\n",
        "                    choices=model_names,\n",
        "                    help='model architecture: ' +\n",
        "                        ' | '.join(model_names) +\n",
        "                        ' (default: resnet50)')\n",
        "# parser.add_argument('-j', '--workers', default=32, type=int, metavar='N',\n",
        "#                     help='number of data loading workers (default: 32)')\n",
        "parser.add_argument('--epochs', default=200, type=int, metavar='N',\n",
        "                    help='number of total epochs to run')\n",
        "parser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n",
        "                    help='manual epoch number (useful on restarts)')\n",
        "parser.add_argument('-b', '--batch-size', default=256, type=int,\n",
        "                    metavar='N',\n",
        "                    help='mini-batch size (default: 256), this is the total '\n",
        "                         'batch size of all GPUs on the current node when '\n",
        "                         'using Data Parallel or Distributed Data Parallel')\n",
        "parser.add_argument('--lr', '--learning-rate', default=0.03, type=float,\n",
        "                    metavar='LR', help='initial learning rate', dest='lr')\n",
        "parser.add_argument('--schedule', default=[120, 160], nargs='*', type=int,\n",
        "                    help='learning rate schedule (when to drop lr by 10x)')\n",
        "parser.add_argument('--momentum', default=0.9, type=float, metavar='M',\n",
        "                    help='momentum of SGD solver')\n",
        "parser.add_argument('--wd', '--weight-decay', default=1e-4, type=float,\n",
        "                    metavar='W', help='weight decay (default: 1e-4)',\n",
        "                    dest='weight_decay')\n",
        "parser.add_argument('-p', '--print-freq', default=10, type=int,\n",
        "                    metavar='N', help='print frequency (default: 10)')\n",
        "parser.add_argument('--resume', default='', type=str, metavar='PATH',\n",
        "                    help='path to latest checkpoint (default: none)')\n",
        "# parser.add_argument('--world-size', default=-1, type=int,\n",
        "#                     help='number of nodes for distributed training')\n",
        "# parser.add_argument('--rank', default=-1, type=int,\n",
        "#                     help='node rank for distributed training')\n",
        "# parser.add_argument('--dist-url', default='tcp://224.66.41.62:23456', type=str,\n",
        "#                     help='url used to set up distributed training')\n",
        "# parser.add_argument('--dist-backend', default='nccl', type=str,\n",
        "#                     help='distributed backend')\n",
        "parser.add_argument('--seed', default=None, type=int,\n",
        "                    help='seed for initializing training. ')\n",
        "parser.add_argument('--gpu', default=None, type=int,\n",
        "                    help='GPU id to use.')\n",
        "# parser.add_argument('--multiprocessing-distributed', action='store_true',\n",
        "#                     help='Use multi-processing distributed training to launch '\n",
        "#                          'N processes per node, which has N GPUs. This is the '\n",
        "#                          'fastest way to use PyTorch for either single node or '\n",
        "#                          'multi node data parallel training')\n",
        "\n",
        "# moco specific configs:\n",
        "parser.add_argument('--moco-dim', default=128, type=int,\n",
        "                    help='feature dimension (default: 128)')\n",
        "parser.add_argument('--moco-k', default=65536, type=int,\n",
        "                    help='queue size; number of negative keys (default: 65536)')\n",
        "parser.add_argument('--moco-m', default=0.999, type=float,\n",
        "                    help='moco momentum of updating key encoder (default: 0.999)')\n",
        "parser.add_argument('--moco-t', default=0.07, type=float,\n",
        "                    help='softmax temperature (default: 0.07)')\n",
        "\n",
        "# options for moco v2\n",
        "parser.add_argument('--mlp', action='store_true',\n",
        "                    help='use mlp head')\n",
        "parser.add_argument('--aug-plus', action='store_true',\n",
        "                    help='use moco v2 data augmentation')\n",
        "parser.add_argument('--cos', action='store_true',\n",
        "                    help='use cosine lr schedule')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "FvLjiq92mAw1"
      },
      "outputs": [],
      "source": [
        "args = parser.parse_args(arg_command)\n",
        "\n",
        "if args.seed is not None:\n",
        "    random.seed(args.seed)\n",
        "    torch.manual_seed(args.seed)\n",
        "    cudnn.deterministic = True\n",
        "    warnings.warn('You have chosen to seed training. '\n",
        "                  'This will turn on the CUDNN deterministic setting, '\n",
        "                  'which can slow down your training considerably! '\n",
        "                  'You may see unexpected behavior when restarting '\n",
        "                  'from checkpoints.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuYf0uhUmAw2"
      },
      "source": [
        "# Training helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "a1wqf6--mAw3"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
        "    torch.save(state, filename)\n",
        "    if is_best:\n",
        "        shutil.copyfile(filename, 'model_best.pth.tar')\n",
        "\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self, name, fmt=':f'):\n",
        "        self.name = name\n",
        "        self.fmt = fmt\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "    def __str__(self):\n",
        "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
        "        return fmtstr.format(**self.__dict__)\n",
        "\n",
        "\n",
        "class ProgressMeter(object):\n",
        "    def __init__(self, file, num_batches, meters, prefix=\"\"):\n",
        "        self.file = file\n",
        "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
        "        self.meters = meters\n",
        "        self.prefix = prefix\n",
        "\n",
        "    def display(self, batch):\n",
        "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
        "        entries += [str(meter) for meter in self.meters]\n",
        "        self.file.write('\\t'.join(entries) + \"\\n\")\n",
        "\n",
        "    def _get_batch_fmtstr(self, num_batches):\n",
        "        num_digits = len(str(num_batches // 1))\n",
        "        fmt = '{:' + str(num_digits) + 'd}'\n",
        "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
        "\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch, args):\n",
        "    \"\"\"Decay the learning rate based on schedule\"\"\"\n",
        "    lr = args.lr\n",
        "    if args.cos:  # cosine lr schedule\n",
        "        lr *= 0.5 * (1. + math.cos(math.pi * epoch / args.epochs))\n",
        "    else:  # stepwise lr schedule\n",
        "        for milestone in args.schedule:\n",
        "            lr *= 0.1 if epoch >= milestone else 1.\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        _, pred = output.topk(maxk, 1, True, True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size))\n",
        "        return res\n",
        "\n",
        "\n",
        "def update_accuracy_meters(losses, top1, top5, output, target, loss, step_size):\n",
        "    \"\"\"Update loss, top1, top5 metrics for either train or validation\n",
        "    Inputs:\n",
        "      - step_size: parameter n for loss/top1/top5 meters\n",
        "    \"\"\"\n",
        "    # acc1/acc5 are (K+1)-way contrast classifier accuracy\n",
        "    # measure accuracy and record loss\n",
        "    acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "    losses.update(loss.item(), step_size)\n",
        "    top1.update(acc1[0], step_size)\n",
        "    top5.update(acc5[0], step_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jKX_SGOmAw4"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "kVr5uUDQmAw4"
      },
      "outputs": [],
      "source": [
        "# Data loading code\n",
        "# traindir = os.path.join(args.data, 'train')\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                  std=[0.229, 0.224, 0.225])\n",
        "if args.aug_plus:\n",
        "    # MoCo v2's aug: similar to SimCLR https://arxiv.org/abs/2002.05709\n",
        "    augmentation = [\n",
        "        # transforms.RandomResizedCrop(224, scale=(0.2, 1.)),\n",
        "        # transforms.RandomApply([\n",
        "        #     transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)  # not strengthened\n",
        "        # ], p=0.8),\n",
        "        # transforms.RandomGrayscale(p=0.2),\n",
        "        transforms.RandomApply([loader.GaussianBlur([.1, 2.])], p=0.5),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        normalize\n",
        "    ]\n",
        "else:\n",
        "    # MoCo v1's aug: the same as InstDisc https://arxiv.org/abs/1805.01978\n",
        "    augmentation = [\n",
        "        # transforms.RandomResizedCrop(224, scale=(0.2, 1.)),\n",
        "        # transforms.RandomGrayscale(p=0.2),\n",
        "        # transforms.ColorJitter(0.4, 0.4, 0.4, 0.4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        normalize\n",
        "    ]\n",
        "\n",
        "train_dataset = medmnist.PathMNIST(\"train\", download=False, root=args.data, \n",
        "                                  #  transform=loader.TwoCropsTransform(transforms.Compose(augmentation)))\n",
        "                                   transform=transforms.Compose(augmentation))\n",
        "val_dataset = medmnist.PathMNIST(\"val\", download=False, root=args.data, \n",
        "                                  #  transform=loader.TwoCropsTransform(transforms.Compose(augmentation)))\n",
        "                                 transform=transforms.Compose(augmentation))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=args.batch_size, shuffle=True, \n",
        "    pin_memory=True, drop_last=True)\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_dataset, batch_size=2 * args.batch_size, shuffle=False, \n",
        "    pin_memory=True, drop_last=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnG87FNTxNNL"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKBaxhUMmAw8",
        "outputId": "12ca19f5-8fb5-4342-baa3-7227bbac1b8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> creating model 'resnet50'\n"
          ]
        }
      ],
      "source": [
        "if WORKING_ENV == 'LABS':\n",
        "  summary = open(trial_name + \".txt\", \"a\")\n",
        "else:\n",
        "  summary = sys.stdout\n",
        "\n",
        "print(\"=> creating model '{}'\".format(args.arch))\n",
        "model = builder.MoCo(\n",
        "    models.__dict__[args.arch],\n",
        "    args.moco_dim, args.moco_k, args.moco_m, args.moco_t, args.mlp)\n",
        "# print(model)\n",
        "\n",
        "if args.gpu is not None:\n",
        "  torch.cuda.set_device(args.gpu)\n",
        "  model = model.cuda(args.gpu)\n",
        "  criterion = nn.CrossEntropyLoss().cuda(args.gpu)\n",
        "else:\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), args.lr,\n",
        "                            momentum=args.momentum,\n",
        "                            weight_decay=args.weight_decay)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxWMJP9cmAxA",
        "outputId": "4beb9c66-d238-444b-937e-3ee38566ed4d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch 101:  15%|█▍        | 102/703 [00:16<11:55,  1.19s/batch, loss=8.56]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [0][100/703]\tTime  0.112 ( 0.112)\tData  0.041 ( 0.039)\tTrainLoss 1.6393e-01 (6.6882e-01)\tValLoss 9.5527e+00 (8.1538e+00)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch 201:  29%|██▊       | 202/703 [00:32<08:31,  1.02s/batch, loss=8.12]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [0][200/703]\tTime  0.116 ( 0.138)\tData  0.039 ( 0.064)\tTrainLoss 6.0632e+00 (3.9999e+00)\tValLoss 1.0437e+01 (8.5183e+00)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch 301:  43%|████▎     | 302/703 [00:48<06:52,  1.03s/batch, loss=7.93]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [0][300/703]\tTime  0.117 ( 0.145)\tData  0.044 ( 0.071)\tTrainLoss 4.8526e+00 (4.8228e+00)\tValLoss 8.9300e+00 (8.2833e+00)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch 401:  57%|█████▋    | 402/703 [01:06<06:33,  1.31s/batch, loss=7.84]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [0][400/703]\tTime  0.203 ( 0.151)\tData  0.094 ( 0.076)\tTrainLoss 5.1543e+00 (5.2385e+00)\tValLoss 8.4798e+00 (8.0804e+00)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch 501:  71%|███████▏  | 502/703 [01:21<03:24,  1.02s/batch, loss=7.61]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [0][500/703]\tTime  0.110 ( 0.154)\tData  0.039 ( 0.079)\tTrainLoss 5.4732e+00 (5.5017e+00)\tValLoss 8.2103e+00 (7.9207e+00)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch 601:  86%|████████▌ | 602/703 [01:37<01:42,  1.02s/batch, loss=7.21]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [0][600/703]\tTime  0.110 ( 0.154)\tData  0.036 ( 0.080)\tTrainLoss 5.4032e+00 (5.6658e+00)\tValLoss 7.7728e+00 (7.7612e+00)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch 701: 100%|█████████▉| 702/703 [01:52<00:01,  1.02s/batch, loss=6.79]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [0][700/703]\tTime  0.120 ( 0.155)\tData  0.046 ( 0.080)\tTrainLoss 5.3689e+00 (5.7505e+00)\tValLoss 7.3211e+00 (7.5907e+00)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch 702: 100%|██████████| 703/703 [01:52<00:00,  6.22batch/s, loss=6.86]\n"
          ]
        }
      ],
      "source": [
        "if args.gpu is not None:\n",
        "  cudnn.benchmark = True\n",
        "\n",
        "for epoch in range(args.start_epoch, args.epochs):\n",
        "    adjust_learning_rate(optimizer, epoch, args)\n",
        "\n",
        "    # train for one epoch\n",
        "    batch_time = AverageMeter('Time', ':6.3f')\n",
        "    data_time = AverageMeter('Data', ':6.3f')\n",
        "    losses = AverageMeter('TrainLoss', ':.4e')\n",
        "    # top1 = AverageMeter('Acc@1', ':6.2f')\n",
        "    # top5 = AverageMeter('Acc@5', ':6.2f')\n",
        "    val_losses = AverageMeter('ValLoss', ':.4e')\n",
        "    # val_top1 = AverageMeter('ValAcc@1', ':6.2f')\n",
        "    # val_top5 = AverageMeter('ValAcc@5', ':6.2f')\n",
        "    progress = ProgressMeter(\n",
        "        summary,\n",
        "        len(train_loader),\n",
        "        # [batch_time, data_time, losses, top1, top5, val_losses, val_top1, val_top5],\n",
        "        [batch_time, data_time, losses, val_losses],\n",
        "        prefix=\"Epoch: [{}]\".format(epoch))\n",
        "\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "\n",
        "    end = time.time()\n",
        "    with tqdm.tqdm(train_loader, unit=\"batch\") as tepoch: \n",
        "      if WORKING_ENV == \"LABS\":\n",
        "        tepoch = train_loader\n",
        "      for i, (images, _) in enumerate(tepoch):\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "\n",
        "        if args.gpu is not None:\n",
        "            images = images.cuda(args.gpu, non_blocking=True)\n",
        "\n",
        "        # compute output\n",
        "        output, target = model(img=images)\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # compute gradient and do SGD step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # update_accuracy_meters(losses, top1, top5, output, target, loss, images[0].size(0))\n",
        "        losses.update(loss.item(), images.size(0))\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if not WORKING_ENV == 'LABS':\n",
        "          tepoch.set_description(f\"batch {i}\")\n",
        "          tepoch.set_postfix(loss=loss.item())\n",
        "\n",
        "        # log performance\n",
        "        if i % args.print_freq == 0 and not i == 0:\n",
        "          with torch.no_grad():\n",
        "            model.eval()\n",
        "            # evaluate on validation set\n",
        "            for (images, _) in val_loader:\n",
        "              if args.gpu is not None:\n",
        "                images = images.cuda(args.gpu, non_blocking=True)\n",
        "              output, target = model(img=images, train=False)\n",
        "              loss = criterion(output, target)\n",
        "              # update_accuracy_meters(val_losses, val_top1, val_top5, output, target, loss, images[0].size(0))\n",
        "              val_losses.update(loss.item(), images.size(0))\n",
        "            \n",
        "            model.train()\n",
        "          \n",
        "          progress.display(i)\n",
        "\n",
        "\n",
        "    # if not args.multiprocessing_distributed or (args.multiprocessing_distributed\n",
        "    #         and args.rank % ngpus_per_node == 0):\n",
        "    #     save_checkpoint({\n",
        "    #         'epoch': epoch + 1,\n",
        "    #         'arch': args.arch,\n",
        "    #         'state_dict': model.state_dict(),\n",
        "    #         'optimizer' : optimizer.state_dict(),\n",
        "    #     }, is_best=False, filename='checkpoint_{:04d}.pth.tar'.format(epoch))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yV8e6GjDH7SY"
      },
      "outputs": [],
      "source": [
        "if WORKING_ENV == 'LABS':\n",
        "  summary.close()\n",
        "\n",
        "torch.save(model, \"model.pickle\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejL5KMHcvoIG",
        "outputId": "45b4188d-b166-4f7b-c120-1677c3f47146"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU RAM Free: 10.4 GB\n",
            "GPU 0 ... Mem Free: 10315MB / 15109MB | Utilization  32%\n"
          ]
        }
      ],
      "source": [
        "mem_report()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OsZtjdy5H7SZ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "med-contrast-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15 (main, Nov 24 2022, 08:29:02) \n[Clang 14.0.6 ]"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "89c22432502bdc03679fbb2d05029bfff3d90287672507a41449dbd4432b55dc"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
