{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKING_ENV = 'LOCAL' #Â Can be LABS, COLAB or PAPERSPACE\n",
    "assert WORKING_ENV in ['LABS', 'COLAB', 'LOCAL']\n",
    "\n",
    "import sys\n",
    "if WORKING_ENV == 'COLAB':\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive/')\n",
    "  !pip install medmnist\n",
    "  !pip install torch\n",
    "  !pip install gputil\n",
    "  !pip install psutil\n",
    "  !pip install humanize\n",
    "  ROOT = \"/content/drive/MyDrive/ColabNotebooks/med-contrastive-project/\"\n",
    "  sys.path.append(ROOT + \"./moco/\")\n",
    "  !nvidia-smi\n",
    "elif WORKING_ENV == 'LABS':\n",
    "  ROOT = \"/vol/bitbucket/sx119/Contrastive-Medical-Image-Classification/\"\n",
    "else:\n",
    "  ROOT = \"/Users/xushitong/Contrastive-Medical-Image-Classification/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import medmnist\n",
    "\n",
    "import argparse\n",
    "import builtins\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import tqdm\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "# import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.multiprocessing as mp\n",
    "import torch.utils.data\n",
    "# import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os,sys,humanize,psutil,GPUtil\n",
    "\n",
    "# Define function\n",
    "def mem_report():\n",
    "  print(\"CPU RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ))\n",
    "  \n",
    "  GPUs = GPUtil.getGPUs()\n",
    "  for i, gpu in enumerate(GPUs):\n",
    "    print('GPU {:d} ... Mem Free: {:.0f}MB / {:.0f}MB | Utilization {:3.0f}%'.format(i, gpu.memoryFree, gpu.memoryTotal, gpu.memoryUtil*100))\n",
    "\n",
    "mem_report()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading code\n",
    "# traindir = os.path.join(args.data, 'train')\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                  std=[0.229, 0.224, 0.225])\n",
    "augmentation = [\n",
    "    transforms.RandomResizedCrop(224, scale=(0.2, 1.)),\n",
    "    transforms.RandomGrayscale(p=0.2),\n",
    "    transforms.ColorJitter(0.4, 0.4, 0.4, 0.4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "]\n",
    "\n",
    "# # legacy split dataset operation, should load splitted data instead\n",
    "# train_dataset = medmnist.PathMNIST(\"train\", download=False, root=args.data, \n",
    "#                                    transform=loader.TwoCropsTransform(transforms.Compose(augmentation)))\n",
    "# val_dataset = medmnist.PathMNIST(\"val\", download=False, root=args.data, \n",
    "#                                    transform=loader.TwoCropsTransform(transforms.Compose(augmentation)))\n",
    "\n",
    "# pretrain_len = int(len(train_dataset) * TRAIN_SET_RATIO)\n",
    "# pretrain_set, pretrain_val_set = torch.utils.data.random_split(train_dataset, [pretrain_len, len(train_dataset) - pretrain_len])\n",
    "# torch.save(pretrain_set, \"pretrain_set.data\")\n",
    "# torch.save(pretrain_val_set, \"pretrain_val_set.data\")\n",
    "\n",
    "# # proper dataset loading, by loading pre-splitted data\n",
    "pretrain_set = torch.load(args.data + \"/pretrain_set.data\")\n",
    "pretrain_val_set = torch.load(args.data + \"/pretrain_val_set.data\")\n",
    "val_dataset = medmnist.PathMNIST(\"val\", download=False, root=args.data, \n",
    "                                   transform=loader.TwoCropsTransform(transforms.Compose(augmentation)))\n",
    "\n",
    "pretrain_loader = torch.utils.data.DataLoader(\n",
    "    pretrain_set, batch_size=args.batch_size, shuffle=True, \n",
    "    pin_memory=True, drop_last=True)\n",
    "pretrain_val_loader = torch.utils.data.DataLoader(\n",
    "    pretrain_val_set, batch_size=2 * args.batch_size, shuffle=False, \n",
    "    pin_memory=True, drop_last=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=2 * args.batch_size, shuffle=False, \n",
    "    pin_memory=True, drop_last=True)\n",
    "\n",
    "print(f\"pretrain size: {len(pretrain_set)}\\npretrain validation size: {len(pretrain_val_set)}\\nvalidation size, {len(val_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = medmnist.PathMNIST(\"train\", download=False, root=args.data)\n",
    "\n",
    "pretrain_len = int(len(train_dataset) * TRAIN_SET_RATIO)\n",
    "pretrain_set, pretrain_val_set = torch.utils.data.random_split(train_dataset, [pretrain_len, len(train_dataset) - pretrain_len])\n",
    "torch.save(pretrain_set, \"pretrain_set.data\")\n",
    "torch.save(pretrain_val_set, \"pretrain_val_set.data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "med-contrast-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "89c22432502bdc03679fbb2d05029bfff3d90287672507a41449dbd4432b55dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
